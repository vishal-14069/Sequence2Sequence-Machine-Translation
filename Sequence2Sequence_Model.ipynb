{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sequence to Sequence Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7r1b2LzrEOOm"
      },
      "outputs": [],
      "source": [
        "def print_line(*args):\n",
        "    args1 = [str(arg) for arg in args]\n",
        "    str_ = ' '.join(args1)\n",
        "    print('\\r' + str_, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YL9CscxMEOOo"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "  \n",
        "  import os\n",
        "  from datasets import load_dataset\n",
        "  dataset_path = os.path.join('a4-data', 'dataset')\n",
        "  ds= load_dataset('iwslt2017', 'iwslt2017-en-fr',cache_dir=dataset_path, verification_mode='no_checks')\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iRHNV8KyEOOp"
      },
      "outputs": [],
      "source": [
        "def prepros_sen(data,lang):\n",
        "  sentences=[]\n",
        "  for i in range(0,len(data)):\n",
        "      sentences.append((data[i][lang].lower()))\n",
        "  return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uemCpDkoEOOq"
      },
      "outputs": [],
      "source": [
        "def load_tokenizer(tokenizer_file):\n",
        "  \n",
        "  from tokenizers import Tokenizer\n",
        "  tokenizer_load= Tokenizer.from_file(tokenizer_file)\n",
        "  return tokenizer_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WeqEL_yaEOOq"
      },
      "outputs": [],
      "source": [
        "def Encode(data,tokenizer):\n",
        "  \n",
        "  token_ids=[]\n",
        "  for i in range(len(data)):\n",
        "      encode2id= tokenizer.encode(data[i])\n",
        "      token_ids.append(encode2id.ids)# token ids are obtained\n",
        "  return token_ids "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qrSjuYzwEOOq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GRU, Embedding,Dropout,Dense,Attention\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Encoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_size, units):\n",
        "    super().__init__()\n",
        "    self.embedding = Embedding(vocab_size, embedding_size) # embedding part \n",
        "    self.gru = GRU(units, return_sequences=True, return_state = True) # gru part \n",
        "\n",
        "  def call(self, source_ids, source_mask):\n",
        "    \"\"\"\n",
        "      Implements the call method of the Encoder class to encode the input.\n",
        "\n",
        "      Args:\n",
        "          source_ids (tf.Tensor): Tensor of source token IDs.\n",
        "          source_mask (tf.Tensor): Tensor of source mask indicating valid tokens.\n",
        "\n",
        "      Returns:\n",
        "          tf.Tensor: Tensor of encoded outputs from the GRU layer.\n",
        "          tf.Tensor: Tensor of final state from the GRU layer.\n",
        "\n",
        "      \"\"\"\n",
        "    source_ids_embeddings = self.embedding(source_ids)\n",
        "    enc_outputs, final_state = self.gru(inputs=source_ids_embeddings, mask=source_mask)\n",
        "    return enc_outputs, final_state\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "agduaETgEOOr"
      },
      "outputs": [],
      "source": [
        "class Decoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_size, units, dropout_rate):\n",
        "    \"\"\"\n",
        "    Decoder class that extends the Model class for a custom decoder model.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): Vocabulary size, representing the number of unique tokens in the output.\n",
        "        embedding_size (int): Size of the embedding vector for each token.\n",
        "        units (int): Number of units in the GRU layer.\n",
        "        dropout_rate (float): Dropout rate for regularization.\n",
        "\n",
        "    \"\"\"\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding = Embedding(vocab_size, embedding_size)\n",
        "    self.dropout = Dropout(dropout_rate)\n",
        "    self.gru = GRU(units, return_sequences=True)\n",
        "    self.classifier = Dense(units=vocab_size)\n",
        "\n",
        "  def call(self, target_ids, initial_state, target_mask):\n",
        "    \"\"\"\n",
        "        Implements the call method of the Decoder class to generate output sequences.\n",
        "\n",
        "        Args:\n",
        "            target_ids (tf.Tensor): Tensor of target token IDs.\n",
        "            initial_state (tf.Tensor): Tensor of initial state for the GRU layer.\n",
        "            target_mask (tf.Tensor): Tensor of target mask indicating valid tokens.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Tensor of generated output sequences from the GRU layer.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "    embedded_target_ids = self.embedding(target_ids)\n",
        "    dec_outputs = self.gru(inputs=embedded_target_ids, mask=target_mask, initial_state=initial_state)\n",
        "    dec_outputs = self.dropout(dec_outputs)\n",
        "    dec_outputs = self.classifier(dec_outputs)\n",
        "    return dec_outputs\n",
        "\n",
        "  def predict(self, target_ids, initial_state):\n",
        "    \"\"\"\n",
        "        Implements the predict method of the Decoder class to generate output sequences during inference.\n",
        "\n",
        "        Args:\n",
        "            target_ids (tf.Tensor): Tensor of target token IDs.\n",
        "            initial_state (tf.Tensor): Tensor of initial state for the GRU layer.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Tensor of generated output sequences from the GRU layer during inference.\n",
        "            tf.Tensor: Tensor of updated state after generating the output sequences.\n",
        "\n",
        "        \"\"\"\n",
        "    gru_cell = self.gru.cell\n",
        "    embedded_target_ids = self.embedding(target_ids)\n",
        "    dec_outputs, state = gru_cell(inputs=embedded_target_ids, states=initial_state, training=False)\n",
        "    dec_outputs = self.classifier(dec_outputs)\n",
        "    return dec_outputs, state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KyX7VAkeEOOr"
      },
      "outputs": [],
      "source": [
        "class Seq2seq(Model):\n",
        "  \"\"\"\n",
        "    Seq2seq class that extends the Model class for a custom sequence-to-sequence model.\n",
        "\n",
        "    Args:\n",
        "        source_vocab_size (int): Vocabulary size of the source language, representing the number of unique tokens.\n",
        "        target_vocab_size (int): Vocabulary size of the target language, representing the number of unique tokens.\n",
        "        embedding_size (int): Size of the embedding vector for each token.\n",
        "        units (int): Number of units in the encoder and decoder GRU layers.\n",
        "        dropout_rate (float): Dropout rate for regularization.\n",
        "\n",
        "    \"\"\"\n",
        "  def __init__(self, source_vocab_size, target_vocab_size, embedding_size, units, dropout_rate):\n",
        "    \n",
        "    super(Seq2seq, self).__init__()\n",
        "    self.encoder = Encoder(vocab_size=source_vocab_size, embedding_size=embedding_size, units=units)\n",
        "    self.decoder = Decoder(vocab_size=target_vocab_size, embedding_size=embedding_size, units=units, dropout_rate=dropout_rate)\n",
        "\n",
        "  def call(self, source_ids, source_seq_lens, target_ids, target_seq_lens):\n",
        "    \"\"\"\n",
        "        Implements the call method of the Seq2seq class for generating output sequences.\n",
        "\n",
        "        Args:\n",
        "            source_ids (tf.Tensor): Tensor of source token IDs.\n",
        "            source_seq_lens (tf.Tensor): Tensor of source sequence lengths.\n",
        "            target_ids (tf.Tensor): Tensor of target token IDs.\n",
        "            target_seq_lens (tf.Tensor): Tensor of target sequence lengths.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Tensor of generated output sequences from the decoder.\n",
        "\n",
        "        \"\"\"\n",
        "    pad_token = fr_tokenizer.token_to_id('<pad>')\n",
        "    enc_outputs, enc_state = self.encoder(source_ids, source_ids != pad_token)\n",
        "    dec_outputs = self.decoder(target_ids, enc_state, target_ids != pad_token)\n",
        "    return dec_outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SK37VXGMEOOs"
      },
      "outputs": [],
      "source": [
        "def seq2seq_loss(outputs, target, seq_lens):\n",
        "  \"\"\"\n",
        "    Computes the sequence-to-sequence loss using cross-entropy with sequence mask.\n",
        "\n",
        "    Args:\n",
        "        outputs (tf.Tensor): Tensor of model outputs, representing the predicted sequences.\n",
        "        target (tf.Tensor): Tensor of target sequences.\n",
        "        seq_lens (tf.Tensor): Tensor of sequence lengths for target sequences.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Tensor of computed loss.\n",
        "\n",
        "    \"\"\"\n",
        "  from tensorflow_addons.seq2seq import sequence_loss\n",
        "  loss = 0\n",
        "  seq_mask = tf.sequence_mask(seq_lens, dtype = tf.dtypes.float32)\n",
        "  loss = sequence_loss(outputs, target, seq_mask, sum_over_timesteps=False, sum_over_batch=False, average_across_batch=True, average_across_timesteps=True)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OerlfKsAEOOs"
      },
      "outputs": [],
      "source": [
        "def source_batch_pad(source_batch, source_seq_lens, pad_val):\n",
        "  \"\"\"\n",
        "    Pads the source batch of sequences with a padding value to ensure equal lengths.\n",
        "\n",
        "    Args:\n",
        "        source_batch (List[List[int]]): List of source sequences in the batch, represented as lists of integers.\n",
        "        source_seq_lens (List[int]): List of source sequence lengths in the batch.\n",
        "        pad_val (int): Padding value to be appended to the sequences.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[tf.Tensor, tf.Tensor]: Tuple of padded source batch and source sequence lengths as tensors.\n",
        "\n",
        "    \"\"\"\n",
        "  padded_source=[]\n",
        "  max_length = max(source_seq_lens)\n",
        "  for i in source_batch:\n",
        "      padded_source.append(i + [pad_val]*(max_length - len(i)))\n",
        "  source_batch = tf.convert_to_tensor(padded_source, dtype=tf.int64)\n",
        "  source_seq_lens_batch = tf.convert_to_tensor(source_seq_lens, dtype=tf.int64)\n",
        "  return source_batch, source_seq_lens_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "avheROeTEOOt"
      },
      "outputs": [],
      "source": [
        "def target_batch_pad(target_batch, target_seq_lens, pad_val):\n",
        "  \"\"\"\n",
        "    Pads the target batch of sequences with a padding value to ensure equal lengths for both input and output sequences.\n",
        "\n",
        "    Args:\n",
        "        target_batch (List[List[int]]): List of target sequences in the batch, represented as lists of integers.\n",
        "        target_seq_lens (List[int]): List of target sequence lengths in the batch.\n",
        "        pad_val (int): Padding value to be appended to the sequences.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[tf.Tensor, tf.Tensor, tf.Tensor]: Tuple of padded target input batch, padded target output batch, and target sequence lengths as tensors.\n",
        "\n",
        "    \"\"\"\n",
        "  target_x_batch, target_y_batch, target_seq_lens_batch = [], [], []\n",
        "  padded_target_x=[]\n",
        "  padded_target_y=[]\n",
        "  for sent, seq_len in zip(target_batch, target_seq_lens):\n",
        "      target_x_batch.append(sent[:-1])\n",
        "      target_y_batch.append(sent[1:])\n",
        "      target_seq_lens_batch.append(seq_len-1)\n",
        "\n",
        "  max_target_length = max(target_seq_lens_batch)\n",
        "  for i,j in zip(target_x_batch,target_y_batch):\n",
        "      padded_target_x.append(i + [pad_val]*(max_target_length - len(i)))\n",
        "      padded_target_y.append(j + [pad_val]*(max_target_length - len(j)))\n",
        "  target_x_batch = tf.convert_to_tensor(padded_target_x, dtype=tf.int64)\n",
        "  target_y_batch = tf.convert_to_tensor(padded_target_y, dtype=tf.int64)\n",
        "  target_seq_lens_batch = tf.convert_to_tensor(target_seq_lens_batch, dtype=tf.int64)\n",
        "  return target_x_batch, target_y_batch, target_seq_lens_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "36fn7T64EOOt"
      },
      "outputs": [],
      "source": [
        "def pad_batch(source_batch, source_seq_lens, target_batch, target_seq_lens, pad_val):\n",
        "  \"\"\"\n",
        "    Pads both source and target batches of sequences with a padding value to ensure equal lengths for input and output sequences.\n",
        "\n",
        "    Args:\n",
        "        source_batch (List[List[int]]): List of source sequences in the batch, represented as lists of integers.\n",
        "        source_seq_lens (List[int]): List of source sequence lengths in the batch.\n",
        "        target_batch (List[List[int]]): List of target sequences in the batch, represented as lists of integers.\n",
        "        target_seq_lens (List[int]): List of target sequence lengths in the batch.\n",
        "        pad_val (int): Padding value to be appended to the sequences.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]: Tuple of padded source batch, source sequence lengths, padded target input batch, padded target output batch, and target sequence lengths as tensors.\n",
        "\n",
        "    \"\"\"\n",
        "  source_batch, source_seq_lens_batch = source_batch_pad(source_batch, source_seq_lens, pad_val)\n",
        "  target_x_batch, target_y_batch, target_seq_lens_batch = target_batch_pad(target_batch, target_seq_lens, pad_val)\n",
        "  return source_batch, source_seq_lens_batch, target_x_batch, target_y_batch, target_seq_lens_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hvmtIz0yEOOt"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import numpy as np \n",
        "class SeqLenBatchSampler:\n",
        "  \"\"\"\n",
        "    Custom batch sampler for generating batches of indices based on sequence lengths.\n",
        "\n",
        "    Args:\n",
        "        seq_lens (List[int]): List of sequence lengths.\n",
        "        batch_size (int): Batch size for generating batches.\n",
        "        seed (int, optional): Seed for random shuffling of batches. Defaults to 6666.\n",
        "\n",
        "    Attributes:\n",
        "        seq_lens (List[int]): List of sequence lengths.\n",
        "        batch_size (int): Batch size for generating batches.\n",
        "        batches (List[List[int]]): List of batches, where each batch is a list of indices.\n",
        "        n_batch (int): Total number of batches.\n",
        "        counter (int): Counter for keeping track of the current batch index during iteration.\n",
        "\n",
        "    \"\"\"\n",
        "  def __init__(self, seq_lens, batch_size, seed: int = 6666):\n",
        "      np.random.seed(seed)\n",
        "      self.seq_lens = seq_lens\n",
        "      self.batch_size = batch_size\n",
        "      self.batches = self._make_batch_index()\n",
        "\n",
        "      self.n_batch = len(self.batches)\n",
        "      self.counter = -1\n",
        "      \n",
        "  def _make_batch_index(self) -> List[List[int]]:\n",
        "      n = len(self.seq_lens)\n",
        "      n_batch = int(np.ceil(n / self.batch_size))\n",
        "      batches = []\n",
        "      # Step 1. Use np.argsort to get all indices with sorted length\n",
        "      # Step 2. Split the indices into batches using a for loop: `for i in range(n_batch):`\n",
        "      sorted_seq_lens = np.argsort(self.seq_lens)\n",
        "      for i in range(n_batch):\n",
        "          start = i * self.batch_size\n",
        "          end = start + self.batch_size\n",
        "          batches.append(sorted_seq_lens[start:end])\n",
        "      return batches\n",
        "  \n",
        "  def __len__(self):\n",
        "      return self.n_batch\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "      return self.batches[index]\n",
        "  \n",
        "  def __iter__(self):\n",
        "      np.random.shuffle(self.batches)\n",
        "      self.counter = -1\n",
        "      return self\n",
        "\n",
        "  def __next__(self):\n",
        "      self.counter += 1\n",
        "      if self.counter < self.n_batch:\n",
        "          return self.batches[self.counter]\n",
        "      raise StopIteration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dLyRBUXeEOOu"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_fr, train_seq_lens_fr, train_en, train_seq_lens_en, fr_val, valid_seq_lens_fr, eng_val, valid_seq_lens_en,\n",
        "              num_epoch, batch_size, optimizer, pad_token_id):\n",
        "  import numpy as np\n",
        "  \"\"\"\n",
        "    Train a sequence-to-sequence model for machine translation.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The sequence-to-sequence model to be trained.\n",
        "        train_fr (List[List[int]]): The training source sequences as lists of token indices.\n",
        "        train_seq_lens_fr (List[int]): The lengths of the training source sequences.\n",
        "        train_en (List[List[int]]): The training target sequences as lists of token indices.\n",
        "        train_seq_lens_en (List[int]): The lengths of the training target sequences.\n",
        "        fr_val (List[List[int]]): The validation source sequences as lists of token indices.\n",
        "        valid_seq_lens_fr (List[int]): The lengths of the validation source sequences.\n",
        "        eng_val (List[List[int]]): The validation target sequences as lists of token indices.\n",
        "        valid_seq_lens_en (List[int]): The lengths of the validation target sequences.\n",
        "        num_epoch (int): The number of epochs to train the model.\n",
        "        batch_size (int): The batch size used for training and validation.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): The optimizer used for model optimization.\n",
        "        pad_token_id (int): The token index for padding in the sequences.\n",
        "\n",
        "    Returns:\n",
        "        train_losses (List[float]): The training losses for each epoch.\n",
        "        valid_losses (List[float]): The validation losses for each epoch.\n",
        "    \"\"\"\n",
        "\n",
        "  n_valid_batch = int(np.ceil(len(fr_val) / batch_size))\n",
        "  train_losses, valid_losses = [], []\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "      epoch_loss = 0.0\n",
        "      for batch_idx, data_index in enumerate(train_batch_sampler):\n",
        "          source_batch, source_seq_lens = train_fr[data_index], train_seq_lens_fr[data_index]\n",
        "          target_batch, target_seq_lens = train_en[data_index], train_seq_lens_en[data_index]\n",
        "          (source_batch, source_seq_lens_batch,\n",
        "            target_x_batch, target_y_batch, target_seq_lens_batch) = pad_batch(source_batch, source_seq_lens,\n",
        "                                                                      target_batch, target_seq_lens,\n",
        "                                                                      pad_val=pad_token_id)\n",
        "\n",
        "          with tf.GradientTape() as tape:\n",
        "              output = model(source_batch, source_seq_lens_batch, target_x_batch, target_seq_lens_batch)\n",
        "              loss = seq2seq_loss(output, target_y_batch, target_seq_lens_batch)\n",
        "\n",
        "          print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {len(train_batch_sampler)} - loss: {loss:.4f}')\n",
        "\n",
        "          trainable_vars = model.trainable_variables\n",
        "          gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "          # Update weights\n",
        "          optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "          epoch_loss += loss * len(source_batch)\n",
        "\n",
        "      valid_loss = 0.0\n",
        "      for batch_idx in range(n_valid_batch):\n",
        "          start = batch_idx * batch_size\n",
        "          end = start + batch_size\n",
        "          source_batch, source_seq_lens = fr_val[start:end], valid_seq_lens_fr[start:end]\n",
        "          target_batch, target_seq_lens = eng_val[start:end], valid_seq_lens_en[start:end]\n",
        "          (source_batch, source_seq_lens_batch,\n",
        "            target_x_batch, target_y_batch, target_seq_lens_batch) = pad_batch(source_batch, source_seq_lens,\n",
        "                                                                      target_batch, target_seq_lens,\n",
        "                                                                      pad_val=pad_token_id)\n",
        "          output = model(source_batch, source_seq_lens_batch, target_x_batch, target_seq_lens_batch, training=False)\n",
        "          loss = seq2seq_loss(output, target_y_batch, target_seq_lens_batch)\n",
        "\n",
        "          if batch_idx % 1 == 0 or batch_idx == len(eng_val) - 1:\n",
        "              print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n",
        "\n",
        "          valid_loss += loss * len(source_batch)\n",
        "\n",
        "      train_epoch_loss = epoch_loss / len(train_fr)\n",
        "      valid_epoch_loss = valid_loss / len(eng_val)\n",
        "      train_losses.append(train_epoch_loss)\n",
        "      valid_losses.append(valid_epoch_loss)\n",
        "      print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {len(train_batch_sampler)} / {len(train_batch_sampler)} - train loss: {train_epoch_loss:.4f} - valid loss: {valid_epoch_loss:.4f}')\n",
        "  return train_losses,valid_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ecKlQJ3BEOOu"
      },
      "outputs": [],
      "source": [
        "def fr_to_eng(encoder,decoder,french_sentences):\n",
        "  \"\"\"\n",
        "    Translates French sentences to English using an encoder-decoder model.\n",
        "\n",
        "    Parameters:\n",
        "        encoder (tf.keras.Model): The encoder model that takes French sentences as input and generates encoder output and final state.\n",
        "        decoder (tf.keras.Model): The decoder model that takes encoder output and final state as input and generates predictions for the next token in the English sentence.\n",
        "        french_sentences (List[List[int]]): A list of French sentences to be translated to English. Each French sentence is represented as a list of integer token IDs.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of predicted English sentences corresponding to the input French sentences.\n",
        "\n",
        "    \"\"\"\n",
        "  pred_sentences = []\n",
        "  for source_ids in french_sentences:\n",
        "      source_ids = tf.expand_dims(tf.convert_to_tensor(source_ids, dtype=tf.int64), axis=0)\n",
        "      encoder_output, final_state = encoder(source_ids, source_ids != pad_token_id)\n",
        "      while [start_os_token_id][-1] != end_os_token_id and len([start_os_token_id]) < max_pred_len:\n",
        "          token = tf.reshape(tf.convert_to_tensor([start_os_token_id][-1]),(1,))\n",
        "          decoder_output, final_state = decoder.predict(token, final_state)\n",
        "          max_index = tf.math.argmax(decoder_output[0]).numpy()\n",
        "          [start_os_token_id].append(max_index)\n",
        "      pred_sentence = eng_tokenizer.decode([start_os_token_id])\n",
        "      pred_sentences.append(pred_sentence)\n",
        "  return pred_sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sacrebleu_score(eng_sentences_test,test_pred):\n",
        "  \"\"\"\n",
        "  Calculate the BLEU score using the SacreBLEU library.\n",
        "\n",
        "  Args:\n",
        "    eng_sentences_test (list): A list of English sentences that serve as the reference translations.\n",
        "    test_pred (list): A list of predicted translations for the English sentences.\n",
        "\n",
        "  Returns:\n",
        "    float: The computed BLEU score.\n",
        "  \"\"\"\n",
        "  import evaluate\n",
        "  import os\n",
        "  dataset_path = os.path.join('a4-data', 'dataset')\n",
        "  sacrebleu = evaluate.load('sacrebleu', cache_dir=dataset_path)\n",
        "  references = []\n",
        "  predictions = []\n",
        "  for i in range(len(eng_sentences_test)):\n",
        "    references.append([eng_sentences_test[i]])\n",
        "    predictions.append(test_pred[i])\n",
        "  results = sacrebleu.compute(predictions=predictions, references=references)\n",
        "  return results['score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "41c0c5cc907040369bdf8283c2d55781",
            "f1983d7b8eb943188eda585727b71a7c",
            "42af25dfa92843efb14ee1ee859d97fa",
            "5626e25298734ea5b8ed9bcbb1fbd1ba",
            "731ade7dbaa2487eb53a4fa2c711f81d",
            "022f1024501a40ba81bcd407637ad85e",
            "170fb270b4f24567a04d5ac9c12f45db",
            "1fea264901a440c1a2be220688f4eb7c",
            "459203a755984a19a972b908f9471815",
            "4e53842df1a549728cabed4677554e6f",
            "c8cbfbb486704f34974e988ea48e1db8"
          ]
        },
        "id": "s5vgS70pEOOu",
        "outputId": "49570748-12ba-439a-bcf7-9c2eaa0c9e46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset iwslt2017 (/Users/vishal./CS584/Assignment 4/a4-data/dataset/iwslt2017/iwslt2017-en-fr/1.0.0/03ce9110373117c6f6687719f49f269486a8cd49dcad2527993a316cd4b6ad49)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfed65c6e8f242bba8600f2ad6794f08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "232825 8597 890\n",
            "Metal device set to: Apple M1 Pro\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-18 15:25:46.628326: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-04-18 15:25:46.628756: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "if __name__== '__main__':\n",
        "\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "   \n",
        "   # Splitting data into train,test and validation\n",
        "    dataset= load_data()\n",
        "    train_data= dataset['train']['translation']\n",
        "    test_data= dataset['test']['translation']\n",
        "    val_data= dataset['validation']['translation']\n",
        "    print(len(train_data),len(test_data),len(val_data))\n",
        "\n",
        "  # Using the prepos function to convert all the text to lower case\n",
        "    eng_sentences_train= prepros_sen(train_data,'en')\n",
        "    eng_sentences_test= prepros_sen(test_data,'en')\n",
        "    eng_sentences_val= prepros_sen(val_data,'en')\n",
        "\n",
        "    fr_sentences_train= prepros_sen(train_data,'fr')\n",
        "    fr_sentences_test= prepros_sen(test_data,'fr')\n",
        "    fr_sentences_val= prepros_sen(val_data,'fr')\n",
        "\n",
        "  # Loading the tokenzier file using the load_tokenzier function\n",
        "    eng_tokenizer= load_tokenizer('en_tokenizer.json')\n",
        "    fr_tokenizer= load_tokenizer('fr_tokenizer.json')\n",
        "  \n",
        "  # Encoding english and french sentences by converting words to token ids using Encode function\n",
        "    eng_train= Encode(eng_sentences_train,eng_tokenizer)\n",
        "    eng_test= Encode(eng_sentences_test,eng_tokenizer)\n",
        "    eng_val= Encode(eng_sentences_val,eng_tokenizer)\n",
        "\n",
        "    fr_train= Encode(fr_sentences_train,fr_tokenizer)\n",
        "    fr_test= Encode(fr_sentences_test,fr_tokenizer)\n",
        "    fr_val= Encode(fr_sentences_val,fr_tokenizer)\n",
        "\n",
        "  # Obtaining the sequence length \n",
        "    np.random.seed(6666)\n",
        "    train_seq_lens_en = [len(en_sent) for en_sent in eng_train]\n",
        "    train_seq_lens_fr = [len(fr_sent) for fr_sent in fr_train]\n",
        "    valid_seq_lens_en = [len(en_sent) for en_sent in eng_val]\n",
        "    valid_seq_lens_fr = [len(fr_sent) for fr_sent in fr_val]\n",
        "    test_seq_lens_en = [len(en_sent) for en_sent in eng_test]\n",
        "    test_seq_lens_fr = [len(fr_sent) for fr_sent in fr_test]\n",
        "\n",
        "    train_en = np.array(eng_train, dtype=object)\n",
        "    train_seq_lens_en = np.array(train_seq_lens_en)\n",
        "    train_fr = np.array(fr_train, dtype=object)\n",
        "    train_seq_lens_fr = np.array(train_seq_lens_fr)\n",
        "  \n",
        "  # Specifying the parameters for the seq2seq model\n",
        "    seed = 6666\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    source_vocab_size = len(fr_tokenizer.get_vocab())\n",
        "    target_vocab_size = len(eng_tokenizer.get_vocab())\n",
        "    hidden_units = 256\n",
        "    embedding_dim = 128\n",
        "    dropout_rate = 0.0\n",
        "    num_epoch = 15\n",
        "    batch_size = 256\n",
        "    learning_rate = 1e-3\n",
        "    pad_token_id= fr_tokenizer.token_to_id('<pad>')\n",
        "    start_os_token_id = eng_tokenizer.token_to_id('<s>')\n",
        "    end_os_token_id = eng_tokenizer.token_to_id('</s>')\n",
        "    max_pred_len = 200\n",
        "\n",
        "    # defining the model\n",
        "    model = Seq2seq(source_vocab_size, target_vocab_size, embedding_dim, hidden_units, dropout_rate)\n",
        "    # defining the optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    #defining the batch sampler\n",
        "    train_batch_sampler = SeqLenBatchSampler(train_seq_lens_fr, batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl3DhkKvEOOw",
        "outputId": "bd189577-d38f-476c-852f-e47fa60aabfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 15 - Step 910 / 910 - train loss: 5.8705 - valid loss: 5.7153\n",
            "Epoch 2 / 15 - Step 910 / 910 - train loss: 4.7454 - valid loss: 4.9459\n",
            "Epoch 3 / 15 - Step 910 / 910 - train loss: 4.1118 - valid loss: 4.6393\n",
            "Epoch 4 / 15 - Step 910 / 910 - train loss: 3.7550 - valid loss: 4.4587\n",
            "Epoch 5 / 15 - Step 910 / 910 - train loss: 3.5060 - valid loss: 4.3174\n",
            "Epoch 6 / 15 - Step 910 / 910 - train loss: 3.3088 - valid loss: 4.2379\n",
            "Epoch 7 / 15 - Step 910 / 910 - train loss: 3.1509 - valid loss: 4.1491\n",
            "Epoch 8 / 15 - Step 910 / 910 - train loss: 3.0229 - valid loss: 4.1121\n",
            "Epoch 9 / 15 - Step 910 / 910 - train loss: 2.9158 - valid loss: 4.0595\n",
            "Epoch 10 / 15 - Step 910 / 910 - train loss: 2.8252 - valid loss: 4.0495\n",
            "Epoch 11 / 15 - Step 910 / 910 - train loss: 2.7489 - valid loss: 4.0382\n",
            "Epoch 12 / 15 - Step 910 / 910 - train loss: 2.6808 - valid loss: 4.0145\n",
            "Epoch 13 / 15 - Step 910 / 910 - train loss: 2.6213 - valid loss: 4.0032\n",
            "Epoch 14 / 15 - Step 910 / 910 - train loss: 2.5694 - valid loss: 4.0006\n",
            "Epoch 15 / 15 - Step 910 / 910 - train loss: 2.5214 - valid loss: 4.0148\n"
          ]
        }
      ],
      "source": [
        "# training the model and obtaining train losses and valid losses\n",
        "train_losses,valid_losses= train_model(model, train_fr, train_seq_lens_fr, train_en, train_seq_lens_en, fr_val, valid_seq_lens_fr, eng_val, valid_seq_lens_en,\n",
        "                num_epoch, batch_size, optimizer, pad_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Dqhe0WuYEOOw"
      },
      "outputs": [],
      "source": [
        "# Prediction of translating french sentences to english sentences by using the french sentences in the test data\n",
        "test_pred = fr_to_eng(model.encoder, model.decoder, fr_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgmx0l4NEOOw",
        "outputId": "d90d41bc-987f-4294-d20e-6897a8a9b565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fr: si vous pensez que celle de gauche est la jazz, et celle de droite est la swing, applaudissez.\n",
            "En: if you think the one on the left is jazz and the one on the right is swing,  clap your hands.\n",
            "Pred_en:  if you think the one hand, the one hand, the one hand, the left is a brown, and it's a secret.\n",
            "\n",
            "\n",
            "Fr: ça poussera beaucoup de monde à regarder, parce que les gens veulent vivre cette expérience.\n",
            "En: it will make tons of people watch,  because people want this experience.\n",
            "Pred_en:  it's a big life on people, because people want to live in this kind of hard experience.\n",
            "\n",
            "\n",
            "Fr: en 2003, mon frère issu d'une autre mère et d'un autre père, dean obeidallah et moi-même, avons créé le festival du rire arabo-américain de new york, qui en est à sa dixième année maintenant.\n",
            "En: in 2003, my brother from another mother and father  dean obeidallah and i started  the new york arab-american comedy festival,  now in its 10th year.\n",
            "Pred_en:  in 2003, my brother and another new generation of mine, and i was a new kind of star that's going to be in the next year, and the father of the year of the year, which is a new generation of mine, the new york times.\n",
            "\n",
            "\n",
            "Fr: j'étais stupéfaite, j'étais très en colère et profondément perplexe.\n",
            "En: and i was astonished,  i was very angry, and i was deeply confused.\n",
            "Pred_en:  i was very fascinated, and i was very angry with my anger.\n",
            "\n",
            "\n",
            "Fr: nous avons les outils avec cette technologie exponentielle.\n",
            "En: we have the tools with this exponential technology.\n",
            "Pred_en:  we have the tools that we have developed with technology.\n",
            "\n",
            "\n",
            "Fr: et c'est là qu'en était la physique il y a quelques années; vous aviez besoin de la mécanique quantique pour décrire de petites, minuscules particules.\n",
            "En: and so that's where physics was at a few years ago;  you needed quantum mechanics  to describe little, tiny particles.\n",
            "Pred_en:  and that's the reason that physics has been a few simple things that you can see, you know, it's a quantum mechanical engineer, you can have a new particle.\n",
            "\n",
            "\n",
            "Fr: aucun ne possède de qualité pharmaceutique réelle. ce n'est que votre croyance qui le rend réel dans votre corps et donne un effet plus fort.\n",
            "En: and none of it has any real pharmaceutical quality,  it's only your belief that makes it real  in your body and makes a stronger effect.\n",
            "Pred_en:  no, you have no value of your own health care: so you can't find your own way to do that, and it's a very strong control of the brain.\n",
            "\n",
            "\n",
            "Fr: mais où peut bien se trouver le défibrillateur automatique le plus proche, pour aider ce patient ?\n",
            "En: but where would be the nearest aed  to help this patient?\n",
            "Pred_en:  but how is the easiest way to the doctor who do the same for the patient?\n",
            "\n",
            "\n",
            "Fr: merci.\n",
            "En: thank you.\n",
            "Pred_en:  thank you.\n",
            "\n",
            "\n",
            "Fr: vous savez, mon métier c'est d'écrire pour les enfants, et je suis probablement l'auteur pour enfants le plus lu d'amérique, en fait.\n",
            "En: you know, what i do is write for children,  and i'm probably america's  most widely read children's author, in fact.\n",
            "Pred_en:  you know, i think i'm teaching girls to be able to read and write, but i think, is the best friend of the children in the school.\n",
            "\n",
            "\n",
            "Fr: mais il y a eu une autre étape intéressante où les choses sont devenues complètement différentes, et c'est que ces cellules ont commencé à échanger et à communiquer des informations de sorte qu'elles ont commencé à avoir des communautés de cellules.\n",
            "En: but then there was another really interesting step  where things became completely different,  which is these cells started exchanging and communicating information,  so that they began to get communities of cells.\n",
            "Pred_en:  but there was a problem that's interesting, and it was interesting to me, and that was the beginning of the building, and it was different from the communities that we started to develop different systems and the cells that were going to work.\n",
            "\n",
            "\n",
            "Fr: alors scott parlait de personne à personne.\n",
            "En: so scott was speaking person-to-person.\n",
            "Pred_en:  and so the audience was talking about nobody.\n",
            "\n",
            "\n",
            "Fr: et je vois greg lemond maintenant.\n",
            "En: and i see greg lemond now.\n",
            "Pred_en:  and i see the gymnian on the right now.\n",
            "\n",
            "\n",
            "Fr: mais l'autre chose est que nous croyons que si nous voyons tous les jours que le gobelet que nous jetons ne disparaît pas, il est toujours quelque part sur la planète.\n",
            "En: but the other thing is that we believe  that if we see every day  that the cup we're throwing away, it doesn't disappear,  it's still somewhere on the planet.\n",
            "Pred_en:  but the other thing we know is that we don't know what we're seeing when we all live in the face of the planet, which is never the end of the day, which is the same thing that we see.\n",
            "\n",
            "\n",
            "Fr: il existe d'autres services comme la façon de fabriquer les l'engrais, ou d'effectuer le transport aérien, où les marges d'amélioration sont beaucoup beaucoup plus réduites.\n",
            "En: there are other services like how we make fertilizer,  or how we do air transport,  where the rooms for improvement are far, far less.\n",
            "Pred_en:  there are other ways of making money, like the money, the way that make it more money, it's a better place, a lot of times more efficient.\n",
            "\n",
            "\n",
            "Fr: ce seront les entrepreneurs, et ils le font en ce moment.\n",
            "En: it will be entrepreneurs, and they're doing it now.\n",
            "Pred_en:  they're the ones who are going to be the ones who are going to go. and they're doing it.\n",
            "\n",
            "\n",
            "Fr: comment dorothy gagne-t-elle dans le film ?\n",
            "En: how does dorothy win her movie?\n",
            "Pred_en:  how do you sleep in a movie about the movie?\n",
            "\n",
            "\n",
            "Fr: une fois, notre bus fût arrêté et un officier de la police chinoise monta à bord.\n",
            "En: one time, our bus was stopped and boarded by a chinese police officer.\n",
            "Pred_en:  once we were in our house, and the police department and the police were a police officer.\n",
            "\n",
            "\n",
            "Fr: je peux, par exemple, dire que j'ai assurément confiance en un certain professeur d'école primaire que je connais pour enseigner à lire à sa classe, mais en aucun cas pour conduire l'autobus scolaire.\n",
            "En: i might, for example, say that i certainly trust  a certain elementary school teacher i know  to teach the reception class to read,  but in no way to drive the school minibus.\n",
            "Pred_en:  i can, for example, i can say, \"i'm a real artist in education,\" because i can't read the school in the school, so i can write a message in the school teaching.\n",
            "\n",
            "\n",
            "Fr: nous avons huit espèces de vautours au kenya, dont six sont fortement menacées d'extinction.\n",
            "En: we have eight species of vultures that occur in kenya,  of which six are highly threatened with extinction.\n",
            "Pred_en:  we have eight-and-a-half species of a species that are in a relatively dangerous place in the united states.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Comparing 20 examples of prediction from the model with the actual sentences\n",
        "# Generate random indices without replacement\n",
        "indices = random.sample(range(len(fr_sentences_test)), 20)\n",
        "\n",
        "# Loop through the selected indices and print the corresponding sentences\n",
        "for i in range(20):\n",
        "    print(f\"Fr: {fr_sentences_test[indices[i]]}\")\n",
        "    print(f\"En: {eng_sentences_test[indices[i]]}\")\n",
        "    print(f\"Pred_en: {test_pred[indices[i]]}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PtTAu1iZ3vX",
        "outputId": "efcb4219-9b19-4a86-ef6d-dca7cdebdc25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.268485393056628"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BLEU_score= sacrebleu_score(eng_sentences_test,test_pred)\n",
        "BLEU_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eYZDeUdkarrH"
      },
      "source": [
        "*   Both the encoder and decoder are built on GRU layers\n",
        "*   Train loss of 2.52 and valid loss of 4 is obtained after training the model for 15 epochs\n",
        "*   BLEU score is used as an evaluation metric to assess the machine translation model\n",
        "*   BLEU score obtained by the model is 7.26\n",
        "*   Coming to the model's performance, the model can be trained more because from the 20 sample predictions we can see that the translation is not accurate\n",
        "*   It is observed that prediction of sentences with a shorter length is better than longer sentences"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "157faed70938b8a4d5156c84022732ece8ba00dcf3b3d99677efa886800b07f9"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "022f1024501a40ba81bcd407637ad85e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170fb270b4f24567a04d5ac9c12f45db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fea264901a440c1a2be220688f4eb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c0c5cc907040369bdf8283c2d55781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1983d7b8eb943188eda585727b71a7c",
              "IPY_MODEL_42af25dfa92843efb14ee1ee859d97fa",
              "IPY_MODEL_5626e25298734ea5b8ed9bcbb1fbd1ba"
            ],
            "layout": "IPY_MODEL_731ade7dbaa2487eb53a4fa2c711f81d"
          }
        },
        "42af25dfa92843efb14ee1ee859d97fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fea264901a440c1a2be220688f4eb7c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_459203a755984a19a972b908f9471815",
            "value": 3
          }
        },
        "459203a755984a19a972b908f9471815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e53842df1a549728cabed4677554e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5626e25298734ea5b8ed9bcbb1fbd1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e53842df1a549728cabed4677554e6f",
            "placeholder": "​",
            "style": "IPY_MODEL_c8cbfbb486704f34974e988ea48e1db8",
            "value": " 3/3 [00:00&lt;00:00, 88.05it/s]"
          }
        },
        "731ade7dbaa2487eb53a4fa2c711f81d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cbfbb486704f34974e988ea48e1db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1983d7b8eb943188eda585727b71a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022f1024501a40ba81bcd407637ad85e",
            "placeholder": "​",
            "style": "IPY_MODEL_170fb270b4f24567a04d5ac9c12f45db",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
